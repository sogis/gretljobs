import ch.so.agi.gretl.tasks.*
import ch.so.agi.gretl.tasks.Curl.MethodType
import ch.so.agi.gretl.api.TransferSet

apply plugin: 'ch.so.agi.gretl'

description = 'GRETL-Job für den Import von Sichtungsmeldungen der Asiatischen Hornisse vom infofauna WFS'

defaultTasks 'copyToEditDb'

// DuckDB
def duckDbPath = "${buildDir}/imported.duckdb"
def duckDbUri = "jdbc:duckdb:${duckDbPath}"
def duckDbFile = file(duckDbPath)

if (duckDbFile.exists()) {
    duckDbFile.delete()
    println 'Deleted existing DuckDB database.'
}

// EditDB
def editDbHost = dbUriEdit.substring(dbUriPub.indexOf("//") + 2, dbUriEdit.lastIndexOf("/"))
def editDbDatabase = dbUriEdit.substring(dbUriEdit.lastIndexOf("/") + 1)
def editDbConnectionString = "'dbname=$editDbDatabase user=$dbUserEdit password=$dbPwdEdit host=$editDbHost'"

// WFS
def wfsUrlEncodedFirstPart = 'https://geoserver.infofauna.ch/geoserver/neovelutina/wfs?Filter=%3CFilter%3E%3CPropertyIsEqualTo%3E%3CPropertyName%3Ecanton%3C%2FPropertyName%3E%3CLiteral%3ESolothurn%3C%2FLiteral%3E%3C%2FPropertyIsEqualTo%3E%3C%2FFilter%3E&SERVICE=WFS&REQUEST=GetFeature&VERSION=2.0.0&TYPENAMES=neovelutina%3A'
def wfsUrlEncodedThirdPart = '&SRSNAME=urn%3Aogc%3Adef%3Acrs%3AEPSG%3A%3A2056&outputFormat=application%2Fjson'
def wfsUrlIndividuals = wfsUrlEncodedFirstPart + 'individuals' + wfsUrlEncodedThirdPart
def wfsUrlActiveNests = wfsUrlEncodedFirstPart + 'active_nests' + wfsUrlEncodedThirdPart
def wfsUrlUnactiveNests = wfsUrlEncodedFirstPart + 'unactive_nests' + wfsUrlEncodedThirdPart

/*
WFS-Abfrage als cURL zum Testen (mit "active_nests" als Beispiel-Layer):
curl --location 'https://geoserver.infofauna.ch/geoserver/neovelutina/wfs?SERVICE=WFS&REQUEST=GetFeature&VERSION=2.0.0&TYPENAMES=neovelutina%3Aactive_nests&SRSNAME=urn%3Aogc%3Adef%3Acrs%3AEPSG%3A%3A2056&Filter=%3CFilter%3E%3CPropertyIsEqualTo%3E%3CPropertyName%3Ecanton%3C%2FPropertyName%3E%3CLiteral%3ESolothurn%3C%2FLiteral%3E%3C%2FPropertyIsEqualTo%3E%3C%2FFilter%3E&outputFormat=application%2Fjson' \
--header 'Authorization: Basic <neovelutinaWfsUser:neovelutinaWfsPwd>'
*/

// Dateipfade
def individualsPath = "'${buildDir}/individuals.geojson'"
def activeNestsPath = "'${buildDir}/active_nests.geojson'"
def unactiveNestsPath = "'${buildDir}/unactive_nests.geojson'"
def individualsFile = file(individualsPath)
def activeNestsFile = file(activeNestsPath)
def unactiveNestsFile = file(unactiveNestsPath)

// Sichtungsmeldungen von Hornissen herunterladen
// tbd: Abfrage auf das laufende Jahr einschränken (so dass Daten für die Dauer einer Saison nachgeführt werden)
tasks.register('downloadIndividuals', Curl) {
    serverUrl = wfsUrlIndividuals
    method = MethodType.GET
    outputFile = individualsFile
    expectedStatusCode = 200
    user = neovelutinaWfsUser
    password = neovelutinaWfsPwd
}

// Sichtungsmeldungen von aktiven Nestern herunterladen
// tbd: Abfrage auf das laufende Jahr einschränken (so dass Daten für die Dauer einer Saison nachgeführt werden)
tasks.register('downloadActiveNests', Curl) {
    serverUrl = wfsUrlActiveNests
    method = MethodType.GET
    outputFile = activeNestsFile
    expectedStatusCode = 200
    user = neovelutinaWfsUser
    password = neovelutinaWfsPwd
}

// Sichtungsmeldungen von zerstörten Nestern herunterladen
// tbd: Abfrage auf das laufende Jahr einschränken (so dass Daten für die Dauer einer Saison nachgeführt werden)
tasks.register('downloadUnactiveNests', Curl) {
    serverUrl = wfsUrlUnactiveNests
    method = MethodType.GET
    outputFile = unactiveNestsFile
    expectedStatusCode = 200
    user = neovelutinaWfsUser
    password = neovelutinaWfsPwd
}

// Heruntergeladene Daten mit DuckDB einlesen
// tbd: sql aufteilen
tasks.register('loadDataToDuckDb', SqlExecutor){
    dependsOn = [downloadIndividuals, downloadActiveNests, downloadUnactiveNests]
    database = [duckDbUri]
    sqlParameters = [
        individuals_path: individualsPath as String,
        active_nests_path: activeNestsPath as String,
        unactive_nests_path: unactiveNestsPath as String
        ]
    sqlFiles = files('create_duckdb_tables.sql')
}

// Bestehende und heruntergeladene Daten in DuckDB zusammenführen
tasks.register('mergeDataInDuckDb', SqlExecutor){
    dependsOn 'loadDataToDuckDb'
    database = [duckDbUri]
    sqlParameters = [
        editdb_connection_string : editDbConnectionString as String
        ]
    sqlFiles = files('merge_duckdb_editdb.sql')
}

// Zusammengeführte Daten in die Edit-DB zurückkopieren
// tbd: das ist ein vorläufiger Entwicklungsstand; Ziel: merge mit bestehenden Daten anstatt overwrite
tasks.register('copyToEditDb', Db2Db) {
    dependsOn 'mergeDataInDuckDb'
    sourceDb = [duckDbUri]
    targetDb = [dbUriEdit, dbUserEdit, dbPwdEdit]
    transferSets = [
        new TransferSet('select_duckdb_individuals.sql', 'afu_asiatische_hornisse_v2.asia_hornisse_sichtung', true, (String[])['geometrie:wkt:2056']),
        new TransferSet('select_duckdb_nests.sql', 'afu_asiatische_hornisse_v2.asia_hornisse_nest', true, (String[])['geometrie:wkt:2056'])
    ];
}